{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Module used to clean Twitter data.\n",
    "\n",
    "Created on Jun 18, 2020\n",
    "\n",
    "@author: mark\n",
    "'''\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import fileinput\n",
    "\n",
    "\n",
    "\n",
    "#English stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "'''\n",
    "Main method to remove stop words, short (2-letter words or less), and clean text.\n",
    "'''\n",
    "def cleanData():\n",
    "    pn=os.path.abspath(\"\")\n",
    "    pn=pn.split(\"src\")[0]  \n",
    "    directory=os.path.join(pn,'results')\n",
    "    output_directory=os.path.join(pn,'modified')\n",
    "    pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "                          \n",
    "    files={}\n",
    "    try:\n",
    "        for f in listdir(directory):\n",
    "            rows=[]\n",
    "            with open(os.path.join(directory,f),'r') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "            \n",
    "            \n",
    "                for row in reader:\n",
    "                    text=row['Text']\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    text=text.lower()\n",
    "                    text=re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', text)\n",
    "                    text=pattern.sub(\"\",text)\n",
    "                    \n",
    "                    word_tokens = word_tokenize(text) \n",
    "                    \n",
    "                    #block of filters to clean sentences\n",
    "                    #removes stop words, @ symbol, http, and various punctuation listed\n",
    "                    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "                    filtered_sentence = [w for w in filtered_sentence if not w.startswith(\"@\")]\n",
    "                    filtered_sentence = [w for w in filtered_sentence if not w.startswith(\"http\")]\n",
    "                    filtered_sentence = [w for w in filtered_sentence if \" amp \" not in w]\n",
    "                    \n",
    "                    #removal of commas, punctuations, brackets, \n",
    "                    words = [w.replace('(', '') for w in filtered_sentence]\n",
    "                    words = [w.replace(')', '') for w in words]\n",
    "                    words = [w.replace('?', '') for w in words]\n",
    "                    words = [w.replace(',', '') for w in words]\n",
    "                    words = [w.replace(\"'\", '') for w in words]\n",
    "                    words = [w.replace('\"', '') for w in words]\n",
    "                    words = [w.replace('!', '') for w in words]\n",
    "                    words = [w.replace(':', '') for w in words]\n",
    "                    words = [w.replace('&amp;', '') for w in words]\n",
    "                    words = [w.replace('.', '') for w in words]\n",
    "                    words = [w.replace('/', '') for w in words]\n",
    "                    words = [w.replace('[', '') for w in words]\n",
    "                    words = [w.replace(']', '') for w in words] \n",
    "                    words = [w for w in words if len(w) > 2]\n",
    "                    \n",
    "                    #re-add cleaned words to tweet text    \n",
    "                    w = \" \".join(words)\n",
    "\n",
    "                    #add text to the dictionary and then the row\n",
    "                    row['Text']=w\n",
    "                    rows.append(row)\n",
    "                \n",
    "                #call the output of the clean data\n",
    "                fle=os.path.join(output_directory,'modified'+\"_\"+f)   \n",
    "                output(rows,fle)  \n",
    "                  \n",
    "            files[f]=rows      \n",
    "    \n",
    "    #exception handling\n",
    "    except IOError:\n",
    "        print (\"Could not read file:\", csvfile)\n",
    "\n",
    "'''\n",
    "Method to output the cleaned data.\n",
    "@param fileOutput- the file output directory\n",
    "'''\n",
    "def output(data,fileOutput):\n",
    "    fieldnames = ['Datetime','ID','Link','Text','Username','Retweets','Hashtags','Geolocation']\n",
    "    with open(fileOutput, 'wt') as csvf:\n",
    "        writer = csv.DictWriter(csvf, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()  \n",
    "        \n",
    "        for f in data:\n",
    "            writer.writerow({'Datetime': str(f['Datetime']),\n",
    "                             'ID':str(f['ID']),'Link':str(f['Link']),\n",
    "                             'Text':str(f['Text']),'Username':str(f['Username']),'Retweets':str(f['Retweets']),'Hashtags':str(f['Hashtags']),\n",
    "                              'Geolocation':str(f['Geolocation'])})\n",
    "    \n",
    "'''\n",
    "The main run method to run the cleanup module.\n",
    "'''        \n",
    "def run():\n",
    "    #clean data\n",
    "    cleanData()\n",
    "    \n",
    "    print('Finished')\n",
    "\n",
    "#calls the run method\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
