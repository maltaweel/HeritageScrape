{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T15:54:47.761881Z",
     "start_time": "2019-11-25T15:54:47.733619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Approach that uses sentiment analysis using the Afinn library.  Sentiment is determined for individual tweets as well as in aggregate based\n",
    "on days when tweets are available.\n",
    "\n",
    "\n",
    "Created on Jun 18, 2020\n",
    "\n",
    "@author: mark\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import collections\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize \n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "from afinn import Afinn\n",
    "from sklearn.metrics.cluster.tests.test_supervised import score_funcs\n",
    "\n",
    "\n",
    "class Sentiment:\n",
    "    \n",
    "    #the Afinn setiment library\n",
    "    afinn = Afinn()\n",
    "    \n",
    "    '''\n",
    "    This determines the affinity (sentiment) score from a tweet.\n",
    "    \n",
    "    @param tweet- the tweet to score\n",
    "    @return score- the sentiment score\n",
    "    '''\n",
    "    def get_affinity_score(self, tweet):\n",
    "        \n",
    "        # the score value\n",
    "        score=0\n",
    "        \n",
    "        #score if the length of the tweet is at least 1\n",
    "        if len(tweet)>0:\n",
    "            score=self.afinn.score(tweet) / len(tweet)\n",
    "            return score\n",
    "        \n",
    "        #otherwise no score\n",
    "        else:\n",
    "            return score\n",
    "            \n",
    "   \n",
    "    '''\n",
    "    Method to load csv data from the modified folder\n",
    "    '''\n",
    "    def loadData(self):\n",
    "        \n",
    "        #get the path for the modified and sentiment directories\n",
    "        pn=os.path.abspath(\"\")\n",
    "        pn=pn.split(\"src\")[0]  \n",
    "        directory=os.path.join(pn,'modified')\n",
    "        output_directory=os.path.join(pn,'sentiment')\n",
    "\n",
    "        #now read the files in the modified directory to get relevant files\n",
    "        try:\n",
    "            \n",
    "            #iteratre through the directory\n",
    "            for f in listdir(directory):\n",
    "                rows=[]\n",
    "                \n",
    "                #skip non-csv files\n",
    "                if '.csv' not in f:\n",
    "                    continue\n",
    "                \n",
    "             \n",
    "                #have containers for the data based on the twitter text, \n",
    "                texts=[]\n",
    "                \n",
    "                #date reference for tweet scores\n",
    "                time={}\n",
    "                \n",
    "                #day-based reference to texts\n",
    "                day={}\n",
    "                \n",
    "                #container for retweets over time\n",
    "                retwts={}\n",
    "                \n",
    "                #open file to read\n",
    "                with open(os.path.join(directory,f),'r') as csvfile:\n",
    "                    reader = csv.DictReader(csvfile)\n",
    "            \n",
    "                    #read the rows\n",
    "                    for row in reader:\n",
    "                        \n",
    "                        #get the tweet text\n",
    "                        text=row['Text']\n",
    "                        \n",
    "                        #the date of the text\n",
    "                        date_time=row['Datetime'].split(\" \")[0]\n",
    "                        \n",
    "                        #covert to a date object (year-month-day)\n",
    "                        date_time_obj = datetime.datetime.strptime(date_time, '%Y-%m-%d')\n",
    "                        \n",
    "                        #put date object in place of datetime in data\n",
    "                        row['Datetime']=date_time_obj.date()\n",
    "                        \n",
    "                        #get retweets\n",
    "                        retweets=int(row['Retweets'])\n",
    "                        \n",
    "                        #get sentiment score of tweet\n",
    "                        score=self.get_affinity_score(text)\n",
    "                        \n",
    "                        #containers for text, sentiment and retweet data\n",
    "                        inputT=[]\n",
    "                        dd=[]\n",
    "                        retweet=[]\n",
    "                        \n",
    "                        #see if current date exists in container\n",
    "                        if  date_time_obj.date() in time:\n",
    "                            \n",
    "                            #organize information based on time\n",
    "                            inputT=time[date_time_obj.date()]\n",
    "                            dd=day[date_time_obj.date()]\n",
    "                            \n",
    "                            #score and text data\n",
    "                            inputT.append(score)\n",
    "                            dd.append(text)\n",
    "                            \n",
    "                            #retweet data\n",
    "                            retweet=retwts[date_time_obj.date()]\n",
    "                            retweet.append(retweets)\n",
    "        \n",
    "                        else:\n",
    "                            \n",
    "                            #if containers do not exist then add to new lists the sentiment, text, and retweet data\n",
    "                            inputT.append(score)\n",
    "                            dd.append(text)\n",
    "                            retweet.append(retweets)\n",
    "                        \n",
    "                        #put data (tweets, sentiment score, and retweets) into dictionaries \n",
    "                        time[date_time_obj.date()]=inputT\n",
    "                        day[date_time_obj.date()]=dd\n",
    "                        retwts[date_time_obj.date()]=retweet\n",
    "                        \n",
    "                        #raw sentiment score for a tweet \n",
    "                        row['Score']=score\n",
    "                        \n",
    "                        #row data are put back to output to individual tweet data in the sentiment folder\n",
    "                        rows.append(row)\n",
    "                        \n",
    "                        #tokenize words\n",
    "                        twords=word_tokenize(text)\n",
    "                        for tt in twords:\n",
    "                            texts.append(tt)\n",
    "                            \n",
    "                #now do word counting to see top words in text\n",
    "                word_counts = Counter(texts)\n",
    "                \n",
    "                #find the 100 most common words for all the data\n",
    "                t=word_counts.most_common(100)\n",
    "                \n",
    "                #most common term output goes to the sentiment output directory\n",
    "                self.most_common_output(t,os.path.join(output_directory,'common_100'+\"_\"+f))\n",
    "                fle=os.path.join(output_directory,'sentiment'+\"_\"+f)       \n",
    "                self.output(rows,fle)\n",
    "                \n",
    "                #call the date-based sentiment output\n",
    "                self.doTimeBasedOutput(time,output_directory,day,retwts,f)\n",
    "                \n",
    "        except IOError:\n",
    "            print (\"Could not read file:\", csvfile)\n",
    "    '''\n",
    "    Method to create time-based output for tweets.\n",
    "    \n",
    "    @param time- The day of when a given tweet is made\n",
    "    @paramr- output_directory- the output directory which is the sentiment directory\n",
    "    @param- day the day reference to associate with twitter data (retweets)\n",
    "    @param- retwts represents the retweet data used\n",
    "    @param- the file to output the results to.\n",
    "    '''\n",
    "    def doTimeBasedOutput(self,date,output_directory,day,retwts,f):\n",
    "        \n",
    "        #fieldnames to output\n",
    "        fieldnames = ['Date','Mean Score','Median Score','Tweets', 'Retweets','Standard Deviation','Top 15']\n",
    "        \n",
    "        #the file output path\n",
    "        fileOutput=os.path.join(output_directory,'sentiment_over_time'+\"_\"+f) \n",
    "        \n",
    "        tts=[]\n",
    "        with open(fileOutput, 'wt') as csvf:\n",
    "            \n",
    "            #write the output file\n",
    "            writer = csv.DictWriter(csvf, fieldnames=fieldnames)\n",
    "            \n",
    "            #write the file header\n",
    "            writer.writeheader() \n",
    "            for t in date:\n",
    "                \n",
    "                #do output based on date. Get the number of tweets, sentiment score, and number of retweets\n",
    "                inpt=date[t]\n",
    "                dd=day[t]\n",
    "                rtweets=retwts[t]\n",
    "                texts=[]\n",
    "\n",
    "                #get the number of tweets\n",
    "                n=len(dd)\n",
    "                \n",
    "                #get the most common terms for a given date\n",
    "                for tt in dd:\n",
    "                    twords=word_tokenize(tt)\n",
    "                    for w in twords:\n",
    "                        texts.append(w)\n",
    "                        tts.append(w)\n",
    "                \n",
    "                #create a word counter\n",
    "                word_counts = Counter(texts)\n",
    "                \n",
    "                #do word counts (top 15 terms for a date)\n",
    "                z=word_counts.most_common(15)\n",
    "                tz=[l for l, t in z]\n",
    "                \n",
    "                #get the mean sentiment score\n",
    "                \n",
    "                #get the standard deviation\n",
    "                mean=np.mean(inpt)\n",
    "                std=np.std(inpt)\n",
    "                \n",
    "                #get the median value\n",
    "                median=np.median(inpt)\n",
    "                \n",
    "                #get the sum of retweets\n",
    "                rts=np.sum(rtweets)\n",
    "            \n",
    "                writer.writerow({'Date': str(t),\n",
    "                             'Mean Score':str(mean),'Median Score':str(median),'Tweets':str(n),\n",
    "                             'Retweets':str(rts),'Standard Deviation':str(std),'Top 15': str(tz)})\n",
    "        \n",
    "       \n",
    "   \n",
    "   \n",
    "        \n",
    "    '''\n",
    "    Method to output the most common terms.\n",
    "    @param t- the term data for most common terms\n",
    "    @param fileOutput- the file to output the results to\n",
    "    '''\n",
    "    def most_common_output(self,t,fileOutput):\n",
    "        \n",
    "        #fieldnames for the output file\n",
    "        fieldnames=[]\n",
    "        \n",
    "        #the output data organized by the most common terms\n",
    "        output={}\n",
    "        for l, d in t:\n",
    "            fieldnames.append(l)\n",
    "            output[l]=d\n",
    "           \n",
    "            \n",
    "        #write the output \n",
    "        with open(fileOutput, 'wt') as csvf:\n",
    "            writer = csv.DictWriter(csvf, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()  \n",
    "            writer.writerow(output)\n",
    "           \n",
    "    '''\n",
    "    Method to output sentiment for individual tweets.\n",
    "    @param data- the data for given tweets\n",
    "    @param fileOutput- the file to output data\n",
    "    '''   \n",
    "    def output(self,data,fileOutput):\n",
    "        \n",
    "        #the fieldnames in the output file\n",
    "        fieldnames = ['Datetime','ID','Score','Link','Text','Username','Retweets','Hashtags','Geolocation']\n",
    "        with open(fileOutput, 'wt') as csvf:\n",
    "            \n",
    "            #write the output\n",
    "            writer = csv.DictWriter(csvf, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()  \n",
    "            \n",
    "            #iterate through data rows and write out\n",
    "            for f in data:\n",
    "                writer.writerow({'Datetime': str(f['Datetime']),\n",
    "                             'ID':str(f['ID']),'Score':str(f['Score']),'Link':str(f['Link']),\n",
    "                             'Text':str(f['Text']),'Username':str(f['Username']),'Retweets':str(f['Retweets']),'Hashtags':str(f['Hashtags']),\n",
    "                              'Geolocation':str(f['Geolocation'])})\n",
    "    \n",
    "    '''\n",
    "    Method to run the sentiment analysis.\n",
    "    '''\n",
    "    def run(self):\n",
    "        #load the data and run analysis\n",
    "        self.loadData()\n",
    "        \n",
    "        #finished\n",
    "        print('Finished')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    s=Sentiment()\n",
    "    s.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T16:40:39.405203Z",
     "start_time": "2019-11-25T16:37:59.060396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Using cached pytest-5.4.3-py3-none-any.whl (248 kB)\n",
      "Collecting more-itertools>=4.0.0\n",
      "  Downloading more_itertools-8.4.0-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 455 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /home/mark/miniconda3/lib/python3.7/site-packages (from pytest) (19.3.0)\n",
      "Requirement already satisfied: wcwidth in /home/mark/miniconda3/lib/python3.7/site-packages (from pytest) (0.1.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /home/mark/miniconda3/lib/python3.7/site-packages (from pytest) (1.6.0)\n",
      "Collecting py>=1.5.0\n",
      "  Downloading py-1.9.0-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pluggy<1.0,>=0.12\n",
      "  Using cached pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mark/miniconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest) (3.1.0)\n",
      "Requirement already satisfied: six in /home/mark/miniconda3/lib/python3.7/site-packages (from packaging->pytest) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/mark/miniconda3/lib/python3.7/site-packages (from packaging->pytest) (2.4.7)\n",
      "\u001b[31mERROR: fastai 1.0.61 requires bottleneck, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.61 requires numexpr, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: cherrypy 18.6.0 requires cheroot>=8.2.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: cherrypy 18.6.0 requires jaraco.collections, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: cherrypy 18.6.0 requires portend>=2.1.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: cherrypy 18.6.0 requires zc.lockfile, which is not installed.\u001b[0m\n",
      "Installing collected packages: more-itertools, py, pluggy, packaging, pytest\n",
      "Successfully installed more-itertools-8.4.0 packaging-20.4 pluggy-0.13.1 py-1.9.0 pytest-5.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:50:27.537768Z",
     "start_time": "2019-11-26T09:50:18.769137Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T16:18:33.901885Z",
     "start_time": "2019-11-25T16:18:33.877144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "1 9\n",
      "2 8\n",
      "3 7\n",
      "4 6\n",
      "5 5\n",
      "6 4\n",
      "7 3\n",
      "8 2\n",
      "9 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T10:57:39.776166Z",
     "start_time": "2019-11-16T10:57:38.268422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's nothing quite like sleeping under the stars. https://t.co/kLkIDjQcmm\n",
      "Really enjoy the Robert Pattinson bender I &amp; the entire rest of the Internet are on right now\n",
      "RT @erspamer_matt: ‘90s kids remember 😍 https://t.co/53swJWJQOK\n",
      "When your friend calls to say they just texted you a clip from an Al Pacino movie https://t.co/EJz80tJryM\n",
      "RT @longdrivesouth: Journalist gets tear-gas direct in the face by #Bolivia police, reports right through it. https://t.co/iy2ysgoh2Q\n",
      "RT @birth_marxist: anything but making transit free. https://t.co/Wtgqmgfvuy\n",
      "RT @degendering: Hello here is your daily reminder that “TERF” is not a synonym for “transphobic person” or “transmisogynist.” \n",
      "Hillary Cli…\n",
      "RT @NoTotally: Anyway this sounds a lot like \"rational\" centrism, which his administration also was, and the mistake of centrism as an ideo…\n",
      "RT @waifujaq: me: *shopping in the men’s section @ the thrift store*\n",
      "grown white men: 👁👁\n",
      "RT @Kurtisaj: Playing Sims 4 University while I’m behind on my actual degree I- https://t.co/oZHlg97YES\n",
      "RT @SJSchauer: Nemo touched the butt and was taken away from his father, a harsh lesson on consent.\n",
      "RT @nealcarter: Spoken like someone whose never been followed in a store for suspicion of stealing despite making purchases. https://t.co/0…\n",
      "RT @iKaylaReed: Update: THEY WON!!!!!!!!!!!!!!! \n",
      "\n",
      "I’m excited like I go there! https://t.co/oqlY0x1adc\n",
      "RT @hermit_hwarang: Indigenous peoples rising up against the fascist coup in Bolivia are being slaughtered by the police. Please don’t igno…\n",
      "RT @MikeGravel: Watch “Democracy” at work in Bolivia. Does this look like a peaceful transition to you?\n",
      "\n",
      " https://t.co/qy2YtOpeax\n",
      "RT @eveewing: thinking about how people are often comfortable in an abstract way admitting they have unearned privilege\n",
      "\n",
      "OR\n",
      "\n",
      "admitting that…\n",
      "RT @greenIight: be gay, steal from corporations, watch movies and shows illegally\n",
      "RT @msdanifernandez: 👉🏻👉🏻👇🏻👇🏻👇🏻👇🏻👇🏻👇🏻👈🏻👈🏻👈🏻\n",
      "👉🏻👉🏻👉🏻👇🏻👇🏻👇🏻👇🏻👇🏻👈🏻👈🏻👈🏻\n",
      "👉🏻👉🏻👉🏻👇🏻👇🏻👇🏻👇🏻👇🏻👈🏽👈🏻👈🏻\n",
      "👉🏻👉🏻👉🏻writers rooms 👈🏻👈🏻👈🏻\n",
      "👉🏻👉🏻that pride themsel…\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T11:04:09.550214Z",
     "start_time": "2019-11-16T11:04:08.995910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @thehill: AG Bill Barr: \"Immediately after President Trump won election, opponents inaugurated what they call 'The Resistance' and they…\n",
      "RT @marklevinshow: Attorney General Bill Barr slams the constant efforts to undermine the president in a speech to the Federalist Society…\n",
      "#NewHoaxSameSwamp https://t.co/GIg9R9Txe0\n",
      "https://t.co/YvlBpfsiTa\n",
      "THANK YOU! #MAGA #KAG https://t.co/Pcq7IbehVp\n",
      "https://t.co/8h6ZmdGlPf https://t.co/shaijXMXli\n",
      "RT @RepLeeZeldin: History is going to be so MASSIVELY unkind towards Pelosi, Schiff and the rest of Congressional Democrats who continue su…\n",
      "RT @RepMarkMeadows: The Democrats second day impeachment witness, Ambassador Yovanovitch, has no information on any of the relevant questio…\n",
      "RT @EliseStefanik: Obama’s own State Dept. was so concerned about conflicts of interest from Hunter Biden’s role at Burisma that they raise…\n",
      "RT @EliseStefanik: The facts are clear, confirmed by our witness, Ambassador Yovanovitch: defensive lethal aid was provided to Ukraine not…\n",
      "RT @SteveScalise: The Dems' star witness was just asked on record if she had any information regarding @realDonaldTrump accepting any bribe…\n",
      "RT @GOPLeader: Before Chairman Adam Schiff gets a chance to make up another phone call between Presidents Trump and Zelensky, @DevinNunes j…\n",
      "RT @Jim_Jordan: https://t.co/gjRFvN02xO\n",
      "RT @DanScavino: “Ukrainian FM Vadym Prystaiko said on Thur that the U.S. Amb did not link financial military assistance to a request for Uk…\n",
      "RT @Jim_Jordan: We now have both the April and July calls between President Trump and President Zelensky. Once again, no linkage of any kin…\n",
      "RT @RepMarkMeadows: Bravo from @RepChrisStewart, who just summarized this whole hearing:\n",
      "\n",
      "Q: \"Do you have any information regarding POTUS a…\n",
      "RT @Rep_Watkins: Democrats didn’t like the outcome of the 2016 election, so now they’re trying to impeach @realDonaldTrump \n",
      "\n",
      "#KS02 #ksleg h…\n",
      "RT @GOPLeader: .@RepStefanik: \"I just want to get it on record. In terms of defensive lethal aid, which you were an advocate for, that was…\n",
      "RT @RepAndyBiggsAZ: .@RepDevinNunes is exactly right: former Ambassador Yovanovitch should not be a witness at an impeachment hearing where…\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>reply_to_status</th>\n",
       "      <th>reply_to_user</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1195582934578798593</td>\n",
       "      <td>RT @thehill: AG Bill Barr: \"Immediately after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5602</td>\n",
       "      <td>2019-11-16 06:02:39</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1195582806212186112</td>\n",
       "      <td>RT @marklevinshow: Attorney General Bill Barr ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6198</td>\n",
       "      <td>2019-11-16 06:02:08</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1195531896433848320</td>\n",
       "      <td>#NewHoaxSameSwamp https://t.co/GIg9R9Txe0</td>\n",
       "      <td>43007</td>\n",
       "      <td>17312</td>\n",
       "      <td>2019-11-16 02:39:50</td>\n",
       "      <td>Twitter Media Studio</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17312</td>\n",
       "      <td>43007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1195500061721026560</td>\n",
       "      <td>https://t.co/YvlBpfsiTa</td>\n",
       "      <td>77180</td>\n",
       "      <td>24375</td>\n",
       "      <td>2019-11-16 00:33:20</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24375</td>\n",
       "      <td>77180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1195495876631957504</td>\n",
       "      <td>THANK YOU! #MAGA #KAG https://t.co/Pcq7IbehVp</td>\n",
       "      <td>43750</td>\n",
       "      <td>12050</td>\n",
       "      <td>2019-11-16 00:16:42</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12050</td>\n",
       "      <td>43750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1195582934578798593  RT @thehill: AG Bill Barr: \"Immediately after ...   \n",
       "1  1195582806212186112  RT @marklevinshow: Attorney General Bill Barr ...   \n",
       "2  1195531896433848320          #NewHoaxSameSwamp https://t.co/GIg9R9Txe0   \n",
       "3  1195500061721026560                            https://t.co/YvlBpfsiTa   \n",
       "4  1195495876631957504      THANK YOU! #MAGA #KAG https://t.co/Pcq7IbehVp   \n",
       "\n",
       "   favorite_count  retweet_count          created_at                source  \\\n",
       "0               0           5602 2019-11-16 06:02:39    Twitter for iPhone   \n",
       "1               0           6198 2019-11-16 06:02:08    Twitter for iPhone   \n",
       "2           43007          17312 2019-11-16 02:39:50  Twitter Media Studio   \n",
       "3           77180          24375 2019-11-16 00:33:20    Twitter for iPhone   \n",
       "4           43750          12050 2019-11-16 00:16:42    Twitter for iPhone   \n",
       "\n",
       "  reply_to_status reply_to_user  retweets  favorites  \n",
       "0            None          None      5602          0  \n",
       "1            None          None      6198          0  \n",
       "2            None          None     17312      43007  \n",
       "3            None          None     24375      77180  \n",
       "4            None          None     12050      43750  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
